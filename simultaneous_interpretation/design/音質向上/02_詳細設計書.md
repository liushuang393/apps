# 詳細設計書 - 音質向上プロジェクト

**文書番号**: DES-2025-001  
**作成日**: 2025-10-26  
**最終更新**: 2025-10-26  
**ステータス**: 🔄 レビュー中  
**バージョン**: 1.0  
**前提文書**: [01_要件定義書.md](./01_要件定義書.md)

---

## 📋 目次

1. [設計概要](#設計概要)
2. [システムアーキテクチャ](#システムアーキテクチャ)
3. [モジュール設計](#モジュール設計)
4. [データ設計](#データ設計)
5. [インターフェース設計](#インターフェース設計)
6. [シーケンス設計](#シーケンス設計)
7. [設定パラメータ](#設定パラメータ)

---

## 1. 設計概要

### 1.1 設計方針

| 原則 | 説明 |
|------|------|
| **モジュール性** | 各機能を独立したモジュールとして実装 |
| **テスタビリティ** | ユニットテスト可能な設計 |
| **拡張性** | 新言語・新機能の追加が容易 |
| **保守性** | コード可読性とドキュメント完備 |

### 1.2 技術スタック

| カテゴリ | 技術 | バージョン |
|----------|------|-----------|
| **言語** | TypeScript | 5.0+ |
| **ランタイム** | Node.js | 18.0+ |
| **フレームワーク** | Electron | 25.0+ |
| **テスト** | Jest | 29.0+ |
| **ビルド** | TypeScript Compiler | 5.0+ |

### 1.3 ディレクトリ構造

```
src/
  ├── audio/
  │   ├── AdaptiveVADBuffer.ts        # 適応的VADバッファ（新規）
  │   ├── VADProcessor.ts              # VAD処理（既存・改修）
  │   ├── AudioValidator.ts            # 音声検証（新規）
  │   ├── StreamingAudioSender.ts     # ストリーミング送信（新規）
  │   └── AudioNoiseProcessor.ts      # ノイズ処理（新規）
  ├── context/
  │   ├── ConversationContext.ts      # 会話コンテキスト（新規）
  │   └── TerminologyManager.ts       # 術語辞書（新規）
  ├── core/
  │   ├── ResponseQueue.ts             # レスポンスキュー（既存・改修）
  │   └── WebSocketManager.ts          # WebSocket管理（既存・改修）
  ├── config/
  │   └── VADConfig.ts                 # VAD設定（新規）
  └── ui/
      └── TerminologyPanel.ts          # 術語管理UI（新規）
```

---

## 2. システムアーキテクチャ

### 2.1 全体構成図

```
┌─────────────────────────────────────────────────────┐
│                   UI Layer                           │
│  ┌──────────────┐  ┌──────────────┐                │
│  │  Settings UI │  │ Terminology  │                │
│  │              │  │  Panel       │                │
│  └──────────────┘  └──────────────┘                │
└─────────────────────────────────────────────────────┘
                        ↕
┌─────────────────────────────────────────────────────┐
│               Business Logic Layer                   │
│  ┌─────────────────────────────────────────────┐   │
│  │  AdaptiveVADBuffer                          │   │
│  │  - 言語別設定                                │   │
│  │  - シナリオ別プリセット                       │   │
│  │  - 適応的閾値調整                            │   │
│  └─────────────────────────────────────────────┘   │
│  ┌─────────────────────────────────────────────┐   │
│  │  ConversationContext                        │   │
│  │  - 履歴管理（最大5発話）                     │   │
│  │  - 術語抽出                                  │   │
│  │  - Instructions 生成                         │   │
│  └─────────────────────────────────────────────┘   │
│  ┌─────────────────────────────────────────────┐   │
│  │  StreamingAudioSender                       │   │
│  │  - 100ms チャンク送信                        │   │
│  │  - VAD連動制御                               │   │
│  └─────────────────────────────────────────────┘   │
└─────────────────────────────────────────────────────┘
                        ↕
┌─────────────────────────────────────────────────────┐
│                 Audio Processing Layer               │
│  ┌──────────────┐  ┌──────────────┐  ┌───────────┐│
│  │ VADProcessor │→│AudioValidator│→│ Encoder   ││
│  └──────────────┘  └──────────────┘  └───────────┘│
│  ┌──────────────┐                                  │
│  │AudioNoise    │ (ノイズ処理)                      │
│  │Processor     │                                  │
│  └──────────────┘                                  │
└─────────────────────────────────────────────────────┘
                        ↕
┌─────────────────────────────────────────────────────┐
│                OpenAI Realtime API                   │
└─────────────────────────────────────────────────────┘
```

### 2.2 データフロー

```
音声入力
  ↓
[1] AudioNoiseProcessor（ノイズ除去）
  ↓
[2] VADProcessor（音声検出）
  ↓
[3] AdaptiveVADBuffer（バッファ管理）
  ↓
[4] AudioValidator（有効性検証）
  ↓
[5] StreamingAudioSender（チャンク送信）
  ↓
[6] WebSocketManager（API通信）
  ↓
[7] ConversationContext（コンテキスト注入）
  ↓
OpenAI Realtime API
  ↓
[8] ResponseQueue（レスポンス管理）
  ↓
翻訳結果出力
```

---

## 3. モジュール設計

### 3.1 AdaptiveVADBuffer（適応的VADバッファ）

#### 3.1.1 クラス定義

```typescript
/**
 * 適応的VADバッファ管理
 * 
 * 目的:
 *   言語・シナリオ・ユーザーパターンに応じて
 *   VADパラメータを動的に調整する
 */
export class AdaptiveVADBuffer {
    private language: string;
    private scenario: ScenarioPreset;
    private recentDurations: number[] = [];
    private recentSilences: number[] = [];
    
    /**
     * パラメータ計算
     * @returns {minDuration, silenceDelay}
     */
    calculateOptimalParams(): {
        minDuration: number;
        silenceDelay: number;
    }
    
    /**
     * 発話記録
     * @param duration 発話時長
     * @param silenceBefore 無音時長
     */
    recordSpeech(duration: number, silenceBefore: number): void
}
```

#### 3.1.2 設定データ

```typescript
// 言語別プリセット
const LANGUAGE_VAD_CONFIG: Record<string, VADConfig> = {
    ja: { min: 1200, silence: 600, threshold: 0.004 },
    en: { min: 1000, silence: 500, threshold: 0.005 },
    zh: { min: 900,  silence: 450, threshold: 0.005 },
    vi: { min: 800,  silence: 400, threshold: 0.006 }
};

// シナリオ別乗数
const SCENARIO_PRESETS: Record<ScenarioPreset, Multiplier> = {
    meeting:      { minMult: 1.3, silenceMult: 1.2 },
    conversation: { minMult: 1.0, silenceMult: 1.0 },
    quickChat:    { minMult: 0.7, silenceMult: 0.8 }
};
```

#### 3.1.3 アルゴリズム

**ステップ1**: 基本値取得
```typescript
const baseConfig = LANGUAGE_VAD_CONFIG[language];
const preset = SCENARIO_PRESETS[scenario];

let minDuration = baseConfig.min * preset.minMult;
let silenceDelay = baseConfig.silence * preset.silenceMult;
```

**ステップ2**: 適応的調整（履歴がある場合）
```typescript
if (this.recentDurations.length >= 5) {
    const avgDuration = average(this.recentDurations);
    const avgSilence = average(this.recentSilences);
    
    // 平均発話時長の70%を下限とする
    minDuration = Math.max(
        minDuration,
        avgDuration * 0.7
    );
    
    // 無声確認は平均無声時長の80%
    silenceDelay = clamp(
        avgSilence * 0.8,
        silenceDelay * 0.5,  // 最小50%
        silenceDelay * 1.5   // 最大150%
    );
}
```

**ステップ3**: ガードレール適用
```typescript
// 基準値の50%～200%の範囲に制限
minDuration = clamp(
    minDuration,
    baseConfig.min * 0.5,
    baseConfig.min * 2.0
);
```

---

### 3.2 ConversationContext（会話コンテキスト）

#### 3.2.1 クラス定義

```typescript
/**
 * 会話コンテキスト管理
 * 
 * 目的:
 *   直近の会話履歴を保持し、翻訳の一貫性を保つ
 */
export class ConversationContext {
    private history: ConversationEntry[] = [];
    private readonly MAX_HISTORY = 5;
    private readonly MAX_AGE_MS = 300000; // 5分
    
    /**
     * エントリ追加
     */
    addEntry(
        sourceText: string,
        translatedText: string,
        language: string
    ): void
    
    /**
     * コンテキスト取得（instructions 用）
     */
    getContext(): string
    
    /**
     * 術語辞書抽出
     */
    extractTerminology(): Map<string, string>
    
    /**
     * リセット
     */
    reset(): void
}
```

#### 3.2.2 データ構造

```typescript
interface ConversationEntry {
    timestamp: number;        // 追加時刻
    sourceText: string;       // 原文
    translatedText: string;   // 訳文
    language: string;         // 言語
}
```

#### 3.2.3 コンテキスト生成アルゴリズム

```typescript
getContext(): string {
    if (this.history.length === 0) {
        return '';
    }
    
    // 最新3件を要約
    const recent = this.history.slice(-3);
    const contextLines = recent.map((entry, index) => {
        return `[${index + 1}] ${entry.sourceText} → ${entry.translatedText}`;
    });
    
    return contextLines.join('\n');
}
```

#### 3.2.4 術語抽出アルゴリズム

```typescript
extractTerminology(): Map<string, string> {
    const terms = new Map<string, string>();
    
    this.history.forEach(entry => {
        // 大文字で始まる単語を固有名詞と判定
        const sourceTerms = entry.sourceText.match(/\b[A-Z][a-z]+\b/g) || [];
        const targetTerms = entry.translatedText.match(/\b[A-Z][a-z]+\b/g) || [];
        
        // 簡易対応付け（出現順）
        sourceTerms.forEach((term, i) => {
            if (targetTerms[i]) {
                terms.set(term, targetTerms[i]);
            }
        });
    });
    
    return terms;
}
```

---

### 3.3 AudioValidator（音声検証）

#### 3.3.1 クラス定義

```typescript
/**
 * 音声データ検証
 * 
 * 目的:
 *   無音・無効なデータを送信しない
 */
export class AudioValidator {
    /**
     * 検証実行
     * @returns {valid, reason}
     */
    validate(audioData: Float32Array): ValidationResult
    
    /**
     * RMS計算
     */
    private calculateRMS(data: Float32Array): number
    
    /**
     * ゼロサンプル比率計算
     */
    private calculateZeroRatio(data: Float32Array): number
}
```

#### 3.3.2 検証ロジック

```typescript
validate(audioData: Float32Array): ValidationResult {
    // 1. 長さチェック
    if (audioData.length < 4800) {  // 200ms @ 24kHz
        return { valid: false, reason: '音声データが短すぎます' };
    }
    
    // 2. エネルギーチェック
    const rms = this.calculateRMS(audioData);
    if (rms < 0.001) {
        return { valid: false, reason: '無音データです' };
    }
    
    // 3. ゼロサンプル比率チェック
    const zeroRatio = this.calculateZeroRatio(audioData);
    if (zeroRatio > 0.95) {
        return { valid: false, reason: 'ほぼ無音です' };
    }
    
    return { valid: true };
}
```

---

### 3.4 StreamingAudioSender（ストリーミング送信）

#### 3.4.1 クラス定義

```typescript
/**
 * ストリーミング音声送信
 * 
 * 目的:
 *   音声データを小分けにして即座に送信し、遅延を削減
 */
export class StreamingAudioSender {
    private buffer: Float32Array[] = [];
    private sendInterval: number | null = null;
    private readonly CHUNK_SIZE = 2400;      // 100ms @ 24kHz
    private readonly SEND_INTERVAL = 100;    // 100ms
    
    /**
     * ストリーミング開始
     */
    start(): void
    
    /**
     * データ追加
     */
    append(data: Float32Array): void
    
    /**
     * ストリーミング停止
     */
    stop(): void
    
    /**
     * バッファフラッシュ
     */
    private flush(): void
}
```

#### 3.4.2 送信アルゴリズム

```typescript
start(): void {
    this.sendInterval = window.setInterval(() => {
        this.flush();
    }, this.SEND_INTERVAL);
}

private flush(): void {
    if (this.buffer.length === 0) return;
    
    // バッファ結合
    const totalLength = this.buffer.reduce((sum, arr) => sum + arr.length, 0);
    const combined = new Float32Array(totalLength);
    let offset = 0;
    
    this.buffer.forEach(arr => {
        combined.set(arr, offset);
        offset += arr.length;
    });
    
    this.buffer = [];
    
    // チャンク分割送信
    for (let i = 0; i < combined.length; i += this.CHUNK_SIZE) {
        const chunk = combined.slice(i, i + this.CHUNK_SIZE);
        this.sendChunk(chunk);
    }
}
```

---

### 3.5 TerminologyManager（術語辞書）

#### 3.5.1 クラス定義

```typescript
/**
 * 術語辞書管理
 * 
 * 目的:
 *   ユーザー辞書とドメイン辞書を管理し、
 *   翻訳の術語一貫性を保つ
 */
export class TerminologyManager {
    private userDict: Map<string, TermEntry> = new Map();
    private domainDicts: Map<string, Map<string, string>> = new Map();
    
    /**
     * ユーザー術語追加
     */
    addUserTerm(entry: TermEntry): void
    
    /**
     * ドメイン辞書ロード
     */
    async loadDomainDict(domain: string): Promise<void>
    
    /**
     * Instructions 生成
     */
    generateInstructions(
        sourceLang: string,
        targetLang: string,
        domain?: string
    ): string
}
```

#### 3.5.2 Instructions 生成

```typescript
generateInstructions(
    sourceLang: string,
    targetLang: string,
    domain?: string
): string {
    let instructions = `${sourceLang}から${targetLang}への同時通訳`;
    
    // ユーザー辞書
    if (this.userDict.size > 0) {
        instructions += '\n\n【必須術語】\n';
        Array.from(this.userDict.values())
            .sort((a, b) => b.priority - a.priority)
            .forEach(entry => {
                instructions += `- "${entry.source}" は必ず "${entry.target}" と訳してください\n`;
            });
    }
    
    // ドメイン辞書
    if (domain && this.domainDicts.has(domain)) {
        const dict = this.domainDicts.get(domain)!;
        instructions += '\n\n【参考術語】\n';
        Array.from(dict.entries()).slice(0, 20).forEach(([src, tgt]) => {
            instructions += `- ${src} → ${tgt}\n`;
        });
    }
    
    return instructions;
}
```

---

### 3.6 AudioNoiseProcessor（ノイズ処理）

#### 3.6.1 クラス定義

```typescript
/**
 * 音声ノイズ処理
 * 
 * 目的:
 *   Web Audio API を使用してノイズを除去
 */
export class AudioNoiseProcessor {
    private audioContext: AudioContext;
    private compressor: DynamicsCompressorNode;
    private lowpass: BiquadFilterNode;
    private highpass: BiquadFilterNode;
    private gainNode: GainNode;
    
    /**
     * コンストラクタ
     */
    constructor(audioContext: AudioContext)
    
    /**
     * 音声ソースに接続
     */
    connect(source: MediaStreamAudioSourceNode): AudioNode
}
```

#### 3.6.2 フィルタ設定

```typescript
constructor(audioContext: AudioContext) {
    this.audioContext = audioContext;
    
    // ハイパスフィルタ（80Hz以下カット）
    this.highpass = audioContext.createBiquadFilter();
    this.highpass.type = 'highpass';
    this.highpass.frequency.value = 80;
    this.highpass.Q.value = 0.7;
    
    // ローパスフィルタ（8kHz以上カット）
    this.lowpass = audioContext.createBiquadFilter();
    this.lowpass.type = 'lowpass';
    this.lowpass.frequency.value = 8000;
    this.lowpass.Q.value = 0.7;
    
    // ダイナミクスコンプレッサー
    this.compressor = audioContext.createDynamicsCompressor();
    this.compressor.threshold.value = -24;
    this.compressor.knee.value = 30;
    this.compressor.ratio.value = 12;
    this.compressor.attack.value = 0.003;
    this.compressor.release.value = 0.25;
    
    // ゲインノード
    this.gainNode = audioContext.createGain();
    this.gainNode.gain.value = 1.2;
    
    // 接続
    this.highpass.connect(this.lowpass);
    this.lowpass.connect(this.compressor);
    this.compressor.connect(this.gainNode);
}
```

---

## 4. データ設計

### 4.1 設定データ構造

```typescript
/**
 * VAD設定
 */
interface VADConfig {
    minSpeechDuration: number;     // 最小発話時長 (ms)
    silenceConfirmDelay: number;   // 無声確認遅延 (ms)
    threshold: number;              // エネルギー閾値
}

/**
 * シナリオ別乗数
 */
interface ScenarioMultiplier {
    minMult: number;               // 最小時長の乗数
    silenceMult: number;           // 無声確認の乗数
}

/**
 * 術語エントリ
 */
interface TermEntry {
    source: string;                // 原語
    target: string;                // 訳語
    domain: string;                // ドメイン
    priority: number;              // 優先度 (1-10)
}

/**
 * 会話エントリ
 */
interface ConversationEntry {
    timestamp: number;             // タイムスタンプ
    sourceText: string;            // 原文
    translatedText: string;        // 訳文
    language: string;              // 言語
}
```

### 4.2 ローカルストレージ

```typescript
// ユーザー設定
interface UserSettings {
    language: string;              // 言語設定
    scenario: ScenarioPreset;      // シナリオ
    vadEnabled: boolean;           // VAD有効/無効
    streamingEnabled: boolean;     // ストリーミング有効/無効
    noiseSuppressionEnabled: boolean; // ノイズ抑制有効/無効
}

// 術語辞書（localStorage）
const TERMINOLOGY_KEY = 'voicetranslate_user_dict';

// 保存
localStorage.setItem(TERMINOLOGY_KEY, JSON.stringify(userDict));

// 読み込み
const saved = localStorage.getItem(TERMINOLOGY_KEY);
if (saved) {
    userDict = JSON.parse(saved);
}
```

---

## 5. インターフェース設計

### 5.1 API インターフェース

#### 5.1.1 OpenAI Realtime API

**Session Update**:
```typescript
interface SessionUpdateMessage {
    type: 'session.update';
    session: {
        model: string;
        modalities: ('text' | 'audio')[];
        instructions: string;
        voice: VoiceType;
        input_audio_format: 'pcm16';
        output_audio_format: 'pcm16';
        turn_detection: TurnDetection | null;
        temperature: number;
        max_response_output_tokens: number;
    };
}
```

**Response Create**:
```typescript
interface ResponseCreateMessage {
    type: 'response.create';
    response: {
        modalities: ('text' | 'audio')[];
        instructions?: string;
    };
}
```

### 5.2 内部API

#### 5.2.1 AdaptiveVADBuffer

```typescript
interface IAdaptiveVADBuffer {
    calculateOptimalParams(): { minDuration: number; silenceDelay: number };
    recordSpeech(duration: number, silenceBefore: number): void;
    reset(): void;
}
```

#### 5.2.2 ConversationContext

```typescript
interface IConversationContext {
    addEntry(sourceText: string, translatedText: string, language: string): void;
    getContext(): string;
    extractTerminology(): Map<string, string>;
    reset(): void;
}
```

#### 5.2.3 AudioValidator

```typescript
interface IAudioValidator {
    validate(audioData: Float32Array): ValidationResult;
}

interface ValidationResult {
    valid: boolean;
    reason?: string;
}
```

---

## 6. シーケンス設計

### 6.1 発話処理シーケンス

```
User                VADProcessor    AdaptiveVADBuffer    AudioValidator    StreamingAudioSender    WebSocket
 |                       |                  |                   |                    |                  |
 |---音声入力----------->|                  |                   |                    |                  |
 |                       |                  |                   |                    |                  |
 |                       |--音声検出------->|                  |                    |                  |
 |                       |                  |                   |                    |                  |
 |                       |                  |--パラメータ取得-->|                    |                  |
 |                       |                  |<------------------|                    |                  |
 |                       |                  |                   |                    |                  |
 |                       |--発話開始------->|                  |                    |--start()-------->|
 |                       |                  |                   |                    |                  |
 |                       |--音声データ----->|                  |--検証------------>|                  |
 |                       |                  |                   |<------------------|                  |
 |                       |                  |                   |                    |                  |
 |                       |                  |                   |                    |--append()------->|
 |                       |                  |                   |                    |                  |
 |                       |                  |                   |                    |--flush()-------->|
 |                       |                  |                   |                    |                  |
 |                       |                  |                   |                    |                  |---send chunk--->API
 |                       |                  |                   |                    |                  |
 |                       |--無声検出------->|                  |                    |                  |
 |                       |                  |                   |                    |                  |
 |                       |                  |--時長チェック---->|                    |                  |
 |                       |                  |<------------------|                    |                  |
 |                       |                  |                   |                    |                  |
 |                       |                  |                   |                    |--stop()--------->|
 |                       |                  |                   |                    |                  |
 |                       |                  |--記録------------>|                    |                  |
 |                       |                  |                   |                    |                  |
```

### 6.2 コンテキスト注入シーケンス

```
VoiceTranslateApp    ConversationContext    TerminologyManager    WebSocketManager    API
       |                     |                        |                    |           |
       |--getContext()------>|                        |                    |           |
       |<--------------------|                        |                    |           |
       |                     |                        |                    |           |
       |--extractTerminology->|                        |                    |           |
       |<--------------------|                        |                    |           |
       |                     |                        |                    |           |
       |--generateInstructions()--------------------->|                    |           |
       |<--------------------------------------------|                    |           |
       |                     |                        |                    |           |
       |--response.create(instructions)-------------->|                    |           |
       |                     |                        |                    |---send--->|
       |                     |                        |                    |           |
       |                     |                        |                    |<--result--|
       |                     |                        |                    |           |
       |<--onResponseDone----|                        |                    |           |
       |                     |                        |                    |           |
       |--addEntry()-------->|                        |                    |           |
       |                     |                        |                    |           |
```

---

## 7. 設定パラメータ

### 7.1 言語別VAD設定

```typescript
export const LANGUAGE_VAD_CONFIG: Record<string, VADConfig> = {
    ja: {
        minSpeechDuration: 1200,
        silenceConfirmDelay: 600,
        threshold: 0.004
    },
    en: {
        minSpeechDuration: 1000,
        silenceConfirmDelay: 500,
        threshold: 0.005
    },
    zh: {
        minSpeechDuration: 900,
        silenceConfirmDelay: 450,
        threshold: 0.005
    },
    vi: {
        minSpeechDuration: 800,
        silenceConfirmDelay: 400,
        threshold: 0.006
    }
};
```

### 7.2 シナリオ別プリセット

```typescript
export const SCENARIO_PRESETS: Record<ScenarioPreset, ScenarioMultiplier> = {
    meeting: {
        minMult: 1.3,        // +30% 長め
        silenceMult: 1.2     // +20% 長め
    },
    conversation: {
        minMult: 1.0,        // 標準
        silenceMult: 1.0     // 標準
    },
    quickChat: {
        minMult: 0.7,        // -30% 短め
        silenceMult: 0.8     // -20% 短め
    }
};
```

### 7.3 ストリーミング設定

```typescript
export const STREAMING_CONFIG = {
    chunkSize: 2400,         // 100ms @ 24kHz
    sendInterval: 100,       // 100ms
    enabled: true
};
```

### 7.4 ノイズ処理設定

```typescript
export const NOISE_PROCESSING_CONFIG = {
    highpass: {
        frequency: 80,       // Hz
        Q: 0.7
    },
    lowpass: {
        frequency: 8000,     // Hz
        Q: 0.7
    },
    compressor: {
        threshold: -24,      // dB
        knee: 30,
        ratio: 12,
        attack: 0.003,       // 3ms
        release: 0.25        // 250ms
    },
    gain: 1.2                // +20%
};
```

---

## 8. テスト設計

### 8.1 ユニットテスト

| モジュール | テストケース数 | カバレッジ目標 |
|-----------|---------------|---------------|
| AdaptiveVADBuffer | 15 | 90% |
| ConversationContext | 12 | 90% |
| AudioValidator | 10 | 95% |
| StreamingAudioSender | 12 | 85% |
| TerminologyManager | 10 | 90% |
| AudioNoiseProcessor | 8 | 80% |

### 8.2 統合テスト

| シナリオ | テスト内容 |
|---------|-----------|
| エンドツーエンド | 音声入力 → 翻訳出力までの全体フロー |
| 言語切替 | 言語変更時のパラメータ切替 |
| シナリオ切替 | モード変更時の挙動 |
| エラーリカバリー | タイムアウト・再送の動作 |

---

## 9. 実装優先順位

### Phase 0: 準備（1週間）

- [ ] プロジェクト構造整備
- [ ] 型定義ファイル作成
- [ ] テスト環境構築

### Phase 1: P0実装（4週間）

1. **Week 1**: AdaptiveVADBuffer + VADConfig
2. **Week 2**: ConversationContext + TerminologyManager
3. **Week 3**: AudioValidator + タイムアウト再送
4. **Week 4**: 統合テスト + 調整

### Phase 2: P1実装（4週間）

5. **Week 5**: StreamingAudioSender
6. **Week 6**: 術語管理UI
7. **Week 7**: プリロード最適化
8. **Week 8**: パフォーマンステスト

### Phase 3: P2実装（3週間）

9. **Week 9**: AudioNoiseProcessor
10. **Week 10**: エコーキャンセル
11. **Week 11**: 最終品質評価

---

## 10. 変更履歴

| バージョン | 日付 | 変更者 | 変更内容 |
|-----------|------|--------|----------|
| 1.0 | 2025-10-26 | AI アシスタント | 初版作成 |

---

**次のステップ**: [03_タスク管理表.md](./03_タスク管理表.md) でタスクを細分化し、実装を開始する


