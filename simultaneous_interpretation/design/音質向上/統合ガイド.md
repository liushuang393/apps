# 新モジュール統合ガイド

**作成日**: 2025-10-26  
**対象**: VoiceTranslate Pro 既存コード  
**目的**: 新実装モジュールの統合手順

---

## 📋 統合概要

### 統合対象モジュール

1. **AdaptiveVADBuffer** - 適応的VADパラメータ管理
2. **AudioValidator** - 音声データ検証
3. **ConversationContext** - 会話履歴管理
4. **TerminologyManager** - 術語辞書管理
5. **StreamingAudioSender** - ストリーミング音声送信
6. **NoiseSuppression** - ノイズ抑制
7. **ResponseQueue (改修版)** - タイムアウト・リトライ機能

---

## 🔧 Step 1: TypeScriptモジュールのビルド

### 1.1 ビルドコマンド実行

```bash
# TypeScriptコンパイル
npm run build:core

# 確認
ls dist/audio/
ls dist/context/
ls dist/core/
```

### 1.2 期待される出力

```
dist/
  audio/
    AdaptiveVADBuffer.js
    AudioValidator.js
    StreamingAudioSender.js
    NoiseSuppression.js
  context/
    ConversationContext.js
    TerminologyManager.js
  core/
    ResponseQueue.js (更新)
```

---

## 🔄 Step 2: ResponseQueue統合

### 2.1 既存コードの確認

現在の `voicetranslate-pro.js`:

```javascript
// 行88-100: 既存のResponseQueue初期化
this.responseQueue = new ResponseQueue((message) => this.sendMessage(message), {
    maxQueueSize: 10,
    timeout: 60000,
    retryOnError: true,
    maxRetries: 2,
    debugMode: CONFIG.DEBUG_MODE,
    onRequestSending: () => {
        this.pendingResponseId = 'pending_' + Date.now();
    }
});
```

### 2.2 統合方法

**Option A: 段階的移行（推奨）**

```javascript
// voicetranslate-pro.js の先頭に追加
import { ResponseQueue } from './dist/core/ResponseQueue.js';

// 初期化コードを更新
this.responseQueue = new ResponseQueue((message) => this.sendMessage(message), {
    maxQueueSize: 10,
    timeout: 30000,      // 30秒に短縮（より厳格）
    maxRetries: 2,       // 最大2回リトライ
    retryBaseDelay: 1000, // 1秒基本遅延
    debugMode: CONFIG.DEBUG_MODE
});
```

**変更点**:
- ✅ `timeout`: 60秒 → 30秒（より厳格なタイムアウト）
- ✅ `retryBaseDelay`: 新規追加（エクスポネンシャルバックオフ）
- ❌ `retryOnError`: 削除（常にリトライ判定）
- ❌ `onRequestSending`: 削除（内部で自動管理）

---

## 🎯 Step 3: AdaptiveVADBuffer統合

### 3.1 インポート追加

```javascript
// voicetranslate-pro.js の先頭
import { AdaptiveVADBuffer } from './dist/audio/AdaptiveVADBuffer.js';
```

### 3.2 初期化

```javascript
constructor() {
    // ... 既存の初期化 ...
    
    // AdaptiveVADBuffer追加
    this.adaptiveVAD = new AdaptiveVADBuffer('ja', 'conversation');
    
    // 初期パラメータを取得
    const vadParams = this.adaptiveVAD.calculateOptimalParams();
    this.minSpeechDuration = vadParams.minDuration;
    this.silenceConfirmDelay = vadParams.silenceDelay;
    
    console.info('[AdaptiveVAD] Initialized:', vadParams);
}
```

### 3.3 言語変更時の更新

```javascript
// 既存の言語変更処理に追加
async updateSourceLanguage(lang) {
    this.state.sourceLang = lang;
    
    // ✅ AdaptiveVADのパラメータを更新
    if (this.adaptiveVAD) {
        this.adaptiveVAD.setLanguage(lang);
        const vadParams = this.adaptiveVAD.calculateOptimalParams();
        this.minSpeechDuration = vadParams.minDuration;
        this.silenceConfirmDelay = vadParams.silenceDelay;
        
        console.info('[AdaptiveVAD] Language updated:', vadParams);
    }
}
```

### 3.4 発話完了時の履歴記録

```javascript
// handleAudioBufferCommitted() 内に追加
handleAudioBufferCommitted() {
    // ... 既存の処理 ...
    
    // ✅ 発話時長を記録（適応的調整用）
    if (this.speechStartTime && this.adaptiveVAD) {
        const duration = Date.now() - this.speechStartTime;
        const silenceBefore = this.silenceConfirmDelay;
        this.adaptiveVAD.recordSpeech(duration, silenceBefore);
        
        if (CONFIG.DEBUG_MODE) {
            console.info('[AdaptiveVAD] Speech recorded:', { duration, silenceBefore });
        }
    }
}
```

---

## 📊 Step 4: AudioValidator統合

### 4.1 インポート

```javascript
import { AudioValidator } from './dist/audio/AudioValidator.js';
```

### 4.2 初期化

```javascript
constructor() {
    // ... 既存の初期化 ...
    
    // AudioValidator追加
    this.audioValidator = new AudioValidator({
        minSampleCount: 4800,    // 200ms @ 24kHz
        minRMSEnergy: 0.001,     // 非常に小さい閾値
        maxZeroRatio: 0.95,      // 95%以上がゼロの場合は無効
        includeDetails: CONFIG.DEBUG_MODE
    });
}
```

### 4.3 音声データ送信前の検証

```javascript
// handleAudioBufferCommitted() 内の送信前に検証
handleAudioBufferCommitted() {
    // ... 既存の処理 ...
    
    // ✅ 音声データを検証
    const audioData = this.getAccumulatedAudioData(); // Float32Array
    const validation = this.audioValidator.validate(audioData);
    
    if (!validation.valid) {
        console.warn('[AudioValidator] Invalid audio data:', validation.reason);
        this.resetAudioBuffer(); // バッファをクリア
        return; // 送信しない
    }
    
    if (CONFIG.DEBUG_MODE && validation.details) {
        console.info('[AudioValidator] Audio quality:', validation.details);
    }
    
    // ... Base64エンコードと送信 ...
}
```

---

## 💬 Step 5: ConversationContext統合

### 5.1 インポート

```javascript
import { ConversationContext } from './dist/context/ConversationContext.js';
```

### 5.2 初期化

```javascript
constructor() {
    // ... 既存の初期化 ...
    
    // ConversationContext追加
    this.conversationContext = new ConversationContext(5, 300000); // 5件、5分
}
```

### 5.3 会話エントリ追加

```javascript
// handleResponseAudioTranscriptDelta() 内に追加
handleResponseAudioTranscriptDelta(delta) {
    // ... 既存の処理 ...
    
    // ✅ 会話履歴に追加（翻訳完了時）
    if (this.conversationContext && this.currentTranslationText) {
        this.conversationContext.addEntry(
            this.currentSourceText || '',        // 原文
            this.currentTranslationText,         // 訳文
            this.state.targetLang || 'en',      // 言語
            0.9                                  // 信頼度（仮）
        );
    }
}
```

### 5.4 WebSocket接続時にコンテキストを送信

```javascript
// createSession() 内で Instructions に追加
async createSession() {
    // ... 既存の処理 ...
    
    // ✅ 会話コンテキストを取得
    let contextString = '';
    if (this.conversationContext) {
        const context = this.conversationContext.getContext();
        if (context.historyCount > 0) {
            contextString = '\n\n【会話履歴】\n' + context.contextString;
        }
    }
    
    const sessionConfig = {
        type: 'session.update',
        session: {
            // ... 既存の設定 ...
            instructions: this.buildInstructions() + contextString
        }
    };
    
    // ... 送信 ...
}
```

---

## 📚 Step 6: TerminologyManager統合

### 6.1 インポート

```javascript
import { TerminologyManager } from './dist/context/TerminologyManager.js';
```

### 6.2 初期化

```javascript
constructor() {
    // ... 既存の初期化 ...
    
    // TerminologyManager追加
    this.terminologyManager = new TerminologyManager();
    
    // LocalStorageから読み込み
    this.terminologyManager.loadFromLocalStorage();
}
```

### 6.3 Instructions生成に統合

```javascript
buildInstructions() {
    // 既存のInstructions生成を置き換え
    if (this.terminologyManager) {
        return this.terminologyManager.generateInstructions({
            sourceLang: this.state.sourceLang || 'auto',
            targetLang: this.state.targetLang || 'en',
            style: 'formal' // またはユーザー設定
        });
    }
    
    // フォールバック（既存の実装）
    return `あなたは${this.state.sourceLang}から${this.state.targetLang}への同時通訳者です。`;
}
```

### 6.4 UI追加（術語辞書管理）

```html
<!-- teams-realtime-translator.html に追加 -->
<div class="terminology-section">
    <h3>術語辞書</h3>
    <div class="terminology-controls">
        <input type="text" id="termSource" placeholder="原語">
        <input type="text" id="termTarget" placeholder="訳語">
        <select id="termDomain">
            <option value="IT">IT</option>
            <option value="medical">医療</option>
            <option value="business">ビジネス</option>
        </select>
        <input type="number" id="termPriority" min="1" max="10" value="5" placeholder="優先度">
        <button id="addTermBtn">追加</button>
    </div>
    <div id="termList"></div>
</div>
```

```javascript
// UI イベントハンドラ
document.getElementById('addTermBtn').addEventListener('click', () => {
    const source = document.getElementById('termSource').value;
    const target = document.getElementById('termTarget').value;
    const domain = document.getElementById('termDomain').value;
    const priority = parseInt(document.getElementById('termPriority').value);
    
    if (source && target) {
        this.terminologyManager.addUserTerm({
            source,
            target,
            domain,
            priority,
            createdAt: Date.now()
        });
        
        // LocalStorageに保存
        this.terminologyManager.saveToLocalStorage();
        
        // UI更新
        this.updateTermList();
        
        // 入力クリア
        document.getElementById('termSource').value = '';
        document.getElementById('termTarget').value = '';
    }
});
```

---

## 🌊 Step 7: StreamingAudioSender統合

### 7.1 インポート

```javascript
import { StreamingAudioSender } from './dist/audio/StreamingAudioSender.js';
```

### 7.2 初期化

```javascript
constructor() {
    // ... 既存の初期化 ...
    
    // StreamingAudioSender追加
    this.streamingSender = new StreamingAudioSender(
        (base64Audio) => this.sendAudioChunk(base64Audio),
        {
            chunkSize: 2400,    // 100ms @ 24kHz
            sendInterval: 100,   // 100ms
            maxBufferSize: 48000 // 2秒
        }
    );
}

// 音声チャンク送信関数
sendAudioChunk(base64Audio) {
    if (this.state.ws && this.state.ws.readyState === WebSocket.OPEN) {
        this.state.ws.send(JSON.stringify({
            type: 'input_audio_buffer.append',
            audio: base64Audio
        }));
    }
}
```

### 7.3 ストリーミング送信開始・停止

```javascript
// 発話開始時
handleSpeechStarted() {
    // ... 既存の処理 ...
    
    // ✅ ストリーミング送信開始
    if (this.streamingSender) {
        this.streamingSender.start();
    }
}

// 発話終了時
handleSpeechEnded() {
    // ... 既存の処理 ...
    
    // ✅ ストリーミング送信停止＋フラッシュ
    if (this.streamingSender) {
        this.streamingSender.flush(); // 残りを送信
        this.streamingSender.stop();
    }
}
```

### 7.4 音声データ追加

```javascript
// 音声処理コールバック内
processAudioData(audioData) {
    // ... 既存の処理 ...
    
    // ✅ ストリーミングバッファに追加
    if (this.streamingSender && this.streamingSender.isActive) {
        this.streamingSender.append(audioData); // Float32Array
        // 自動的に100msごとに送信される
    }
}
```

---

## 🔇 Step 8: NoiseSuppression統合

### 8.1 インポート

```javascript
import { NoiseSuppression } from './dist/audio/NoiseSuppression.js';
```

### 8.2 初期化

```javascript
constructor() {
    // ... 既存の初期化 ...
    
    // NoiseSuppression追加
    this.noiseSuppression = new NoiseSuppression({
        highpassFreq: 100,   // 100Hz
        lowpassFreq: 8000,   // 8kHz
        gain: 1.0,
        enabled: true
    });
}
```

### 8.3 音声キャプチャ時に適用

```javascript
async startMicrophoneCapture() {
    // ... MediaStream取得 ...
    const stream = await navigator.mediaDevices.getUserMedia({
        audio: {
            echoCancellation: true,
            noiseSuppression: true, // ブラウザのノイズ抑制も併用
            autoGainControl: true
        }
    });
    
    // ✅ ノイズサプレッション適用
    if (this.noiseSuppression) {
        const processedStream = this.noiseSuppression.apply(
            stream,
            this.state.audioContext
        );
        
        // processedStream.stream を使用
        this.state.audioSource = this.state.audioContext.createMediaStreamSource(
            processedStream.stream
        );
    }
    
    // ... 既存の音声処理パイプライン接続 ...
}
```

---

## 🎛️ Step 9: UI設定追加

### 9.1 設定パネル拡張

```html
<!-- teams-realtime-translator.html に追加 -->
<div class="advanced-settings">
    <h3>高度な設定</h3>
    
    <!-- シナリオ選択 -->
    <div class="setting-item">
        <label for="scenarioSelect">シナリオ:</label>
        <select id="scenarioSelect">
            <option value="meeting">会議（精度優先）</option>
            <option value="conversation" selected>日常会話（バランス）</option>
            <option value="quickChat">短対話（速度優先）</option>
        </select>
    </div>
    
    <!-- ノイズ抑制ON/OFF -->
    <div class="setting-item">
        <label>
            <input type="checkbox" id="noiseSuppressionCheck" checked>
            ノイズ抑制
        </label>
    </div>
    
    <!-- ストリーミング送信ON/OFF -->
    <div class="setting-item">
        <label>
            <input type="checkbox" id="streamingCheck" checked>
            ストリーミング送信（低遅延）
        </label>
    </div>
</div>
```

### 9.2 イベントハンドラ

```javascript
// シナリオ変更
document.getElementById('scenarioSelect').addEventListener('change', (e) => {
    if (this.adaptiveVAD) {
        this.adaptiveVAD.setScenario(e.target.value);
        const params = this.adaptiveVAD.calculateOptimalParams();
        this.minSpeechDuration = params.minDuration;
        this.silenceConfirmDelay = params.silenceDelay;
        console.info('[UI] Scenario changed:', params);
    }
});

// ノイズ抑制ON/OFF
document.getElementById('noiseSuppressionCheck').addEventListener('change', (e) => {
    if (this.noiseSuppression) {
        this.noiseSuppression.updateConfig({ enabled: e.target.checked });
        console.info('[UI] Noise suppression:', e.target.checked);
    }
});
```

---

## ✅ Step 10: 統合テスト

### 10.1 テストシナリオ

1. **基本動作テスト**
   - [ ] マイク音声認識
   - [ ] 翻訳実行
   - [ ] 音声再生

2. **AdaptiveVAD テスト**
   - [ ] 言語変更時のパラメータ更新
   - [ ] シナリオ変更時の動作確認
   - [ ] 履歴記録と適応調整

3. **AudioValidator テスト**
   - [ ] 無音データの拒否
   - [ ] 短すぎるデータの拒否
   - [ ] 有効データの通過

4. **ResponseQueue テスト**
   - [ ] タイムアウト動作
   - [ ] リトライ動作
   - [ ] エクスポネンシャルバックオフ

5. **ConversationContext テスト**
   - [ ] 会話履歴保存
   - [ ] コンテキスト生成
   - [ ] 5件制限

6. **TerminologyManager テスト**
   - [ ] 術語追加・削除
   - [ ] LocalStorage永続化
   - [ ] Instructions生成

7. **StreamingAudioSender テスト**
   - [ ] チャンク分割送信
   - [ ] 100ms間隔確認
   - [ ] flush動作

8. **NoiseSuppression テスト**
   - [ ] ノイズ除去効果
   - [ ] ON/OFF切り替え
   - [ ] パラメータ変更

---

## 📝 統合チェックリスト

### コード変更
- [ ] TypeScriptビルド実行 (`npm run build:core`)
- [ ] インポート文追加（8モジュール）
- [ ] 初期化コード追加
- [ ] 既存処理への統合

### テスト
- [ ] ESLint チェック (`npm run lint`)
- [ ] TypeScript型チェック (`npm run type-check`)
- [ ] ユニットテスト実行 (`npm test`)
- [ ] 統合テスト実行

### ドキュメント
- [ ] CHANGELOG更新
- [ ] README更新
- [ ] API ドキュメント作成

### デプロイ
- [ ] ステージング環境テスト
- [ ] パフォーマンス計測
- [ ] プロダクション デプロイ

---

## 🚨 注意事項

### 1. 互換性

既存の機能を壊さないよう、段階的に統合してください：

```javascript
// ❌ 悪い例: 一度にすべて置き換え
constructor() {
    // 既存コードを全削除して新コードに置き換え
}

// ✅ 良い例: 段階的に追加
constructor() {
    // 既存の初期化を保持
    this.initExistingFeatures();
    
    // 新機能を追加
    if (CONFIG.ENABLE_ADAPTIVE_VAD) {
        this.adaptiveVAD = new AdaptiveVADBuffer('ja', 'conversation');
    }
}
```

### 2. フィーチャーフラグ

新機能は初期状態で無効化可能にしてください：

```javascript
// config に追加
const CONFIG = {
    // ... 既存の設定 ...
    
    // 新機能フラグ
    ENABLE_ADAPTIVE_VAD: true,
    ENABLE_AUDIO_VALIDATOR: true,
    ENABLE_CONVERSATION_CONTEXT: true,
    ENABLE_TERMINOLOGY: true,
    ENABLE_STREAMING_SENDER: false, // 初期は無効
    ENABLE_NOISE_SUPPRESSION: true
};
```

### 3. エラーハンドリング

すべての新機能にエラーハンドリングを追加：

```javascript
try {
    if (this.adaptiveVAD) {
        const params = this.adaptiveVAD.calculateOptimalParams();
        // ...
    }
} catch (error) {
    console.error('[AdaptiveVAD] Error:', error);
    // フォールバック: 既存の固定値を使用
    this.minSpeechDuration = 1000;
    this.silenceConfirmDelay = 500;
}
```

---

## 📊 期待される改善効果

統合完了後、以下の改善が期待されます：

| 指標 | 改善前 | 改善後 | 測定方法 |
|-----|-------|-------|---------|
| 文漏れ率 | 5-8% | < 2% | 100発話テスト |
| E2E遅延 (p50) | 1.8s | < 1.2s | パフォーマンス計測 |
| 術語一貫性 | 60% | > 85% | 術語出現率 |
| ノイズ耐性 | SNR 10dB: CER +15% | < +5% | ノイズ環境テスト |

---

**次のアクション**: Step 1から順番に実施してください。


