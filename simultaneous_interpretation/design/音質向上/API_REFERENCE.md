# VoiceTranslate Pro - éŸ³è³ªå‘ä¸Šæ©Ÿèƒ½ API ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ

## ğŸ“š æ¦‚è¦

ã“ã®ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã¯ã€VoiceTranslate Pro ã®éŸ³è³ªå‘ä¸Šæ©Ÿèƒ½ã® API ãƒªãƒ•ã‚¡ãƒ¬ãƒ³ã‚¹ã§ã™ã€‚

---

## ğŸ“¦ ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ä¸€è¦§

### 1. AdaptiveVADBuffer

**å ´æ‰€**: `src/audio/AdaptiveVADBuffer.ts`

è¨€èªãƒ»ã‚·ãƒŠãƒªã‚ªãƒ»ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ç™ºè©±ãƒ‘ã‚¿ãƒ¼ãƒ³ã«å¿œã˜ã¦VADãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’å‹•çš„ã«èª¿æ•´ã—ã¾ã™ã€‚

#### ã‚³ãƒ³ã‚¹ãƒˆãƒ©ã‚¯ã‚¿

```typescript
constructor(language: string, scenario: ScenarioPreset = 'conversation')
```

**ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿**:
- `language`: è¨€èªã‚³ãƒ¼ãƒ‰ ('ja' | 'en' | 'zh' | 'vi')
- `scenario`: ã‚·ãƒŠãƒªã‚ª ('meeting' | 'conversation' | 'quickChat')

#### ãƒ¡ã‚½ãƒƒãƒ‰

##### calculateOptimalParams()

```typescript
calculateOptimalParams(): VADParameters
```

æœ€é©ãªVADãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’è¨ˆç®—ã—ã¾ã™ã€‚

**æˆ»ã‚Šå€¤**:
```typescript
{
    minDuration: number;        // æœ€å°ç™ºè©±æ™‚é•· (ms)
    silenceDelay: number;       // ç„¡å£°ç¢ºèªé…å»¶ (ms)
    language: string;           // ä½¿ç”¨è¨€èª
    scenario: ScenarioPreset;   // ä½¿ç”¨ã‚·ãƒŠãƒªã‚ª
    adaptiveApplied: boolean;   // é©å¿œèª¿æ•´ãŒé©ç”¨ã•ã‚ŒãŸã‹
}
```

##### recordSpeech()

```typescript
recordSpeech(duration: number, silenceBefore: number): void
```

ç™ºè©±ã‚’è¨˜éŒ²ã—ã¦é©å¿œçš„èª¿æ•´ã«ä½¿ç”¨ã—ã¾ã™ã€‚

**ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿**:
- `duration`: ç™ºè©±æ™‚é•· (ms)
- `silenceBefore`: ç™ºè©±å‰ã®ç„¡å£°æ™‚é•· (ms)

##### setLanguage()

```typescript
setLanguage(language: string): void
```

è¨€èªã‚’å¤‰æ›´ã—ã¾ã™ï¼ˆå±¥æ­´ã¯ãƒªã‚»ãƒƒãƒˆã•ã‚Œã¾ã™ï¼‰ã€‚

##### setScenario()

```typescript
setScenario(scenario: ScenarioPreset): void
```

ã‚·ãƒŠãƒªã‚ªã‚’å¤‰æ›´ã—ã¾ã™ã€‚

---

### 2. AudioValidator

**å ´æ‰€**: `src/audio/AudioValidator.ts`

éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã®æœ‰åŠ¹æ€§ã‚’æ¤œè¨¼ã—ã€ç„¡éŸ³ãƒ»ç„¡åŠ¹ãªãƒ‡ãƒ¼ã‚¿ã®é€ä¿¡ã‚’é˜²ãã¾ã™ã€‚

#### ã‚³ãƒ³ã‚¹ãƒˆãƒ©ã‚¯ã‚¿

```typescript
constructor(config?: Partial<AudioValidationConfig>)
```

**ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè¨­å®š**:
```typescript
{
    minSampleCount: 4800,    // 200ms @ 24kHz
    minRMSEnergy: 0.001,
    maxZeroRatio: 0.95,
    includeDetails: false
}
```

#### ãƒ¡ã‚½ãƒƒãƒ‰

##### validate()

```typescript
validate(audioData: Float32Array): ValidationResult
```

éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã‚’æ¤œè¨¼ã—ã¾ã™ã€‚

**æˆ»ã‚Šå€¤**:
```typescript
{
    valid: boolean;
    reason?: string;
    details?: ValidationDetails;
}
```

##### calculateRMS()

```typescript
calculateRMS(data: Float32Array): number
```

RMSï¼ˆRoot Mean Squareï¼‰ã‚¨ãƒãƒ«ã‚®ãƒ¼ã‚’è¨ˆç®—ã—ã¾ã™ã€‚

##### calculateQualityMetrics()

```typescript
calculateQualityMetrics(data: Float32Array): AudioQualityMetrics
```

è©³ç´°ãªå“è³ªãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’è¨ˆç®—ã—ã¾ã™ã€‚

---

### 3. StreamingAudioSender

**å ´æ‰€**: `src/audio/StreamingAudioSender.ts`

éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã‚’å°ã•ãªãƒãƒ£ãƒ³ã‚¯ã«åˆ†å‰²ã—ã¦ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°é€ä¿¡ã—ã¾ã™ã€‚

#### ã‚³ãƒ³ã‚¹ãƒˆãƒ©ã‚¯ã‚¿

```typescript
constructor(
    sendFn: SendAudioChunkFunction,
    config?: Partial<StreamingAudioSenderConfig>
)
```

**ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè¨­å®š**:
```typescript
{
    chunkSize: 2400,        // 100ms @ 24kHz
    sendInterval: 100,      // 100ms
    maxBufferSize: 48000    // 2ç§’ @ 24kHz
}
```

#### ãƒ¡ã‚½ãƒƒãƒ‰

##### start()

```typescript
start(): void
```

ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°é€ä¿¡ã‚’é–‹å§‹ã—ã¾ã™ã€‚

##### stop()

```typescript
stop(): void
```

ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°é€ä¿¡ã‚’åœæ­¢ã—ã¾ã™ã€‚

##### append()

```typescript
append(audioData: Float32Array): void
```

éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã‚’ãƒãƒƒãƒ•ã‚¡ã«è¿½åŠ ã—ã¾ã™ï¼ˆè‡ªå‹•çš„ã«é€ä¿¡ã•ã‚Œã¾ã™ï¼‰ã€‚

##### flush()

```typescript
flush(): void
```

ã™ã¹ã¦ã®ãƒãƒƒãƒ•ã‚¡ã‚’ãƒ•ãƒ©ãƒƒã‚·ãƒ¥ã—ã¦é€ä¿¡ã—ã¾ã™ã€‚

---

### 4. NoiseSuppression

**å ´æ‰€**: `src/audio/NoiseSuppression.ts`

Web Audio API ã‚’ä½¿ç”¨ã—ã¦ãƒã‚¤ã‚ºã‚’æŠ‘åˆ¶ã—ã¾ã™ã€‚

#### ã‚³ãƒ³ã‚¹ãƒˆãƒ©ã‚¯ã‚¿

```typescript
constructor(config?: Partial<NoiseSuppressionConfig>)
```

**ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè¨­å®š**:
```typescript
{
    highpassFreq: 100,   // 100Hz
    lowpassFreq: 8000,   // 8kHz
    gain: 1.0,
    enabled: true
}
```

#### ãƒ¡ã‚½ãƒƒãƒ‰

##### apply()

```typescript
apply(
    stream: MediaStream,
    audioContext: AudioContext
): MediaStreamAudioDestinationNode
```

ãƒã‚¤ã‚ºã‚µãƒ—ãƒ¬ãƒƒã‚·ãƒ§ãƒ³ã‚’é©ç”¨ã—ã¾ã™ã€‚

**æˆ»ã‚Šå€¤**: å‡¦ç†æ¸ˆã¿ã® MediaStreamAudioDestinationNode

##### updateConfig()

```typescript
updateConfig(config: Partial<NoiseSuppressionConfig>): void
```

è¨­å®šã‚’å‹•çš„ã«æ›´æ–°ã—ã¾ã™ã€‚

##### dispose()

```typescript
dispose(): void
```

ãƒªã‚½ãƒ¼ã‚¹ã‚’è§£æ”¾ã—ã¾ã™ã€‚

---

### 5. ConversationContext

**å ´æ‰€**: `src/context/ConversationContext.ts`

ä¼šè©±å±¥æ­´ã‚’ç®¡ç†ã—ã€ç¿»è¨³ã®ä¸€è²«æ€§ã‚’ä¿ã¡ã¾ã™ã€‚

#### ã‚³ãƒ³ã‚¹ãƒˆãƒ©ã‚¯ã‚¿

```typescript
constructor(maxHistory: number = 5, maxAgeMs: number = 300000)
```

**ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿**:
- `maxHistory`: æœ€å¤§å±¥æ­´ä»¶æ•°ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 5ï¼‰
- `maxAgeMs`: æœ€å¤§å¹´é½¢ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 5åˆ†ï¼‰

#### ãƒ¡ã‚½ãƒƒãƒ‰

##### addEntry()

```typescript
addEntry(
    sourceText: string,
    translatedText: string,
    language: string,
    confidence?: number
): void
```

ä¼šè©±ã‚¨ãƒ³ãƒˆãƒªã‚’è¿½åŠ ã—ã¾ã™ã€‚

##### getContext()

```typescript
getContext(options?: ContextGenerationOptions): ContextInfo
```

ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆæƒ…å ±ã‚’å–å¾—ã—ã¾ã™ã€‚

**æˆ»ã‚Šå€¤**:
```typescript
{
    contextString: string;
    terminology: Map<string, string>;
    historyCount: number;
    oldestTimestamp: number | null;
}
```

---

### 6. TerminologyManager

**å ´æ‰€**: `src/context/TerminologyManager.ts`

è¡“èªè¾æ›¸ã‚’ç®¡ç†ã—ã€ç¿»è¨³ã®è¡“èªä¸€è²«æ€§ã‚’ä¿ã¡ã¾ã™ã€‚

#### ãƒ¡ã‚½ãƒƒãƒ‰

##### addUserTerm()

```typescript
addUserTerm(entry: TermEntry): void
```

ãƒ¦ãƒ¼ã‚¶ãƒ¼è¡“èªã‚’è¿½åŠ ã—ã¾ã™ã€‚

**TermEntry**:
```typescript
{
    source: string;
    target: string;
    domain: string;
    priority: number;    // 1-10
    createdAt: number;
}
```

##### generateInstructions()

```typescript
generateInstructions(params: InstructionsParams): string
```

OpenAI API ç”¨ã® Instructions ã‚’ç”Ÿæˆã—ã¾ã™ã€‚

**ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿**:
```typescript
{
    sourceLang: string;
    targetLang: string;
    domain?: string;
    customInstructions?: string;
    style?: 'formal' | 'casual' | 'technical';
}
```

##### saveToLocalStorage()

```typescript
saveToLocalStorage(key?: string): void
```

LocalStorage ã«ä¿å­˜ã—ã¾ã™ã€‚

##### loadFromLocalStorage()

```typescript
loadFromLocalStorage(key?: string): number
```

LocalStorage ã‹ã‚‰èª­ã¿è¾¼ã¿ã¾ã™ã€‚æˆ»ã‚Šå€¤ã¯èª­ã¿è¾¼ã¾ã‚ŒãŸè¡“èªæ•°ã€‚

---

### 7. ResponseQueue (æ”¹ä¿®ç‰ˆ)

**å ´æ‰€**: `src/core/ResponseQueue.ts`

ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã¨ãƒªãƒˆãƒ©ã‚¤æ©Ÿèƒ½ã‚’æŒã¤ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚­ãƒ¥ãƒ¼ã€‚

#### ã‚³ãƒ³ã‚¹ãƒˆãƒ©ã‚¯ã‚¿

```typescript
constructor(
    sendMessageFn: SendMessageFunction<T>,
    options: ResponseQueueOptions = {}
)
```

**æ–°ã—ã„ã‚ªãƒ—ã‚·ãƒ§ãƒ³**:
```typescript
{
    maxQueueSize?: number;
    timeout?: number;           // NEW: ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ 30ç§’
    maxRetries?: number;        // NEW: ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ 2å›
    retryBaseDelay?: number;    // NEW: ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ 1ç§’
    debugMode?: boolean;
}
```

#### ãƒ¡ã‚½ãƒƒãƒ‰

##### enqueue()

```typescript
enqueue(request: T): Promise<string>
```

ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’ã‚­ãƒ¥ãƒ¼ã«è¿½åŠ ã—ã¾ã™ã€‚ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆãƒ»ãƒªãƒˆãƒ©ã‚¤ã‚’è‡ªå‹•å‡¦ç†ã—ã¾ã™ã€‚

##### handleResponseDone()

```typescript
handleResponseDone(responseId: string): void
```

ãƒ¬ã‚¹ãƒãƒ³ã‚¹å®Œäº†ã‚’é€šçŸ¥ã—ã¾ã™ï¼ˆã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã‚¿ã‚¤ãƒãƒ¼ã‚’ã‚¯ãƒªã‚¢ï¼‰ã€‚

##### handleError()

```typescript
handleError(error: Error, code?: string): void
```

ã‚¨ãƒ©ãƒ¼ã‚’å‡¦ç†ã—ã¾ã™ï¼ˆå¿…è¦ã«å¿œã˜ã¦ãƒªãƒˆãƒ©ã‚¤ï¼‰ã€‚

##### getStats()

```typescript
getStats(): QueueStats
```

çµ±è¨ˆæƒ…å ±ã‚’å–å¾—ã—ã¾ã™ã€‚

**æˆ»ã‚Šå€¤**:
```typescript
{
    totalRequests: number;
    completedRequests: number;
    failedRequests: number;
    retriedRequests: number;      // NEW
    timeoutRequests: number;      // NEW
    pendingCount: number;
    processingCount: number;
}
```

---

## ğŸ”§ ä½¿ç”¨ä¾‹

### åŸºæœ¬çš„ãªä½¿ã„æ–¹

```typescript
// 1. AdaptiveVADBuffer
const vadBuffer = new AdaptiveVADBuffer('ja', 'meeting');
const params = vadBuffer.calculateOptimalParams();
console.log('VAD Params:', params);

// ç™ºè©±å®Œäº†å¾Œã«è¨˜éŒ²
vadBuffer.recordSpeech(1500, 600);

// 2. AudioValidator
const validator = new AudioValidator();
const result = validator.validate(audioData);

if (!result.valid) {
    console.warn('Invalid audio:', result.reason);
    return;
}

// 3. StreamingAudioSender
const sender = new StreamingAudioSender((base64Audio) => {
    ws.send(JSON.stringify({
        type: 'input_audio_buffer.append',
        audio: base64Audio
    }));
}, {
    chunkSize: 2400,
    sendInterval: 100
});

sender.start();
sender.append(audioData);
sender.flush();
sender.stop();

// 4. NoiseSuppression
const noiseSuppression = new NoiseSuppression({
    highpassFreq: 100,
    lowpassFreq: 8000
});

const processedStream = noiseSuppression.apply(stream, audioContext);

// 5. ConversationContext
const context = new ConversationContext(5, 300000);
context.addEntry('Hello', 'ã“ã‚“ã«ã¡ã¯', 'en');

const info = context.getContext();
console.log('Context:', info.contextString);

// 6. TerminologyManager
const termManager = new TerminologyManager();
termManager.addUserTerm({
    source: 'AI',
    target: 'äººå·¥çŸ¥èƒ½',
    domain: 'IT',
    priority: 10,
    createdAt: Date.now()
});

const instructions = termManager.generateInstructions({
    sourceLang: 'en',
    targetLang: 'ja',
    style: 'formal'
});

// 7. ResponseQueue (æ”¹ä¿®ç‰ˆ)
const queue = new ResponseQueue(sendFn, {
    timeout: 30000,
    maxRetries: 2,
    retryBaseDelay: 1000
});

try {
    const responseId = await queue.enqueue(request);
    console.log('Response:', responseId);
} catch (error) {
    console.error('Request failed:', error);
}
```

---

## ğŸ“– è©³ç´°ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ

- [çµ±åˆã‚¬ã‚¤ãƒ‰](./çµ±åˆã‚¬ã‚¤ãƒ‰.md)
- [æœ€çµ‚å®Œäº†å ±å‘Šæ›¸](./æœ€çµ‚å®Œäº†å ±å‘Šæ›¸.md)
- [ã‚¿ã‚¹ã‚¯ç®¡ç†è¡¨](./03_ã‚¿ã‚¹ã‚¯ç®¡ç†è¡¨.md)

---

**æœ€çµ‚æ›´æ–°**: 2025-10-26


