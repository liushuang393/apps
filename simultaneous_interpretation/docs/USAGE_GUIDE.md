# ä½¿ç”¨ã‚¬ã‚¤ãƒ‰ - VoiceTranslate Pro 2.0

## ğŸ“š ç›®æ¬¡

1. [ã‚¯ã‚¤ãƒƒã‚¯ã‚¹ã‚¿ãƒ¼ãƒˆ](#ã‚¯ã‚¤ãƒƒã‚¯ã‚¹ã‚¿ãƒ¼ãƒˆ)
2. [ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ä½¿ç”¨ä¾‹](#ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ä½¿ç”¨ä¾‹)
3. [è¨­å®šæ–¹æ³•](#è¨­å®šæ–¹æ³•)
4. [ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°](#ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°)

---

## ã‚¯ã‚¤ãƒƒã‚¯ã‚¹ã‚¿ãƒ¼ãƒˆ

### ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«

```bash
# ä¾å­˜é–¢ä¿‚ã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
npm install

# é–‹ç™ºã‚µãƒ¼ãƒãƒ¼ã®èµ·å‹•
npm run dev

# ãƒ“ãƒ«ãƒ‰
npm run build
```

### åŸºæœ¬çš„ãªä½¿ç”¨æ–¹æ³•

```typescript
import {
    AppConfig,
    BrowserWebSocketAdapter,
    AudioPipeline,
    VADProcessor,
    ResamplerProcessor,
    EncoderProcessor,
    ErrorHandler,
    LatencyOptimizer
} from './src';

// 1. è¨­å®šã®åˆæœŸåŒ–
AppConfig.loadFromEnv();

// 2. WebSocket ã‚¢ãƒ€ãƒ—ã‚¿ãƒ¼ã®ä½œæˆ
const wsAdapter = new BrowserWebSocketAdapter();
await wsAdapter.initialize({
    url: AppConfig.API.REALTIME_URL,
    model: AppConfig.API.REALTIME_MODEL,
    apiKey: 'your-api-key'
});

// 3. éŸ³å£°å‡¦ç†ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã®æ§‹ç¯‰
const pipeline = new AudioPipeline();
pipeline.addProcessor(new VADProcessor());
pipeline.addProcessor(new ResamplerProcessor({ targetSampleRate: 24000, quality: 'high' }));
pipeline.addProcessor(new EncoderProcessor({ format: 'pcm16' }));
await pipeline.initialize();

// 4. ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒ©ãƒ¼ã®è¨­å®š
const errorHandler = new ErrorHandler();

// 5. é…å»¶æœ€é©åŒ–ã®è¨­å®š
const latencyOptimizer = new LatencyOptimizer();
latencyOptimizer.setWebSocketAdapter(wsAdapter);

// 6. æ¥ç¶š
await wsAdapter.connect();
```

---

## ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ä½¿ç”¨ä¾‹

### 1. WebSocket ã‚¢ãƒ€ãƒ—ã‚¿ãƒ¼

#### ãƒ–ãƒ©ã‚¦ã‚¶ç’°å¢ƒ

```typescript
import { BrowserWebSocketAdapter } from './src/adapters';

const adapter = new BrowserWebSocketAdapter();

await adapter.initialize({
    url: 'wss://api.openai.com/v1/realtime',
    model: 'gpt-realtime-2025-08-28',
    apiKey: 'your-api-key',
    reconnect: {
        enabled: true,
        maxAttempts: 5,
        initialDelay: 1000,
        maxDelay: 30000,
        backoffMultiplier: 2
    }
}, {
    onOpen: () => console.log('Connected'),
    onMessage: (msg) => console.log('Message:', msg),
    onError: (err) => console.error('Error:', err),
    onClose: (code, reason) => console.log('Closed:', code, reason)
});

await adapter.connect();

// ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸é€ä¿¡
await adapter.send({ type: 'session.update', session: { ... } });

// ãƒã‚¤ãƒŠãƒªãƒ‡ãƒ¼ã‚¿é€ä¿¡
await adapter.sendBinary(audioBuffer);

// åˆ‡æ–­
await adapter.disconnect();
```

#### Electron ç’°å¢ƒ

```typescript
import { ElectronWebSocketAdapter } from './src/adapters';

const adapter = new ElectronWebSocketAdapter();

// ãƒ¡ã‚¤ãƒ³ãƒ—ãƒ­ã‚»ã‚¹ã«æ¥ç¶š
await adapter.connectToMainProcess();

// ä»¥é™ã¯ãƒ–ãƒ©ã‚¦ã‚¶ç‰ˆã¨åŒã˜
await adapter.initialize({ ... });
await adapter.connect();
```

---

### 2. éŸ³å£°å‡¦ç†ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³

```typescript
import {
    AudioPipeline,
    AudioPipelineBuilder,
    VADProcessor,
    ResamplerProcessor,
    EncoderProcessor
} from './src/audio';

// ãƒ“ãƒ«ãƒ€ãƒ¼ãƒ‘ã‚¿ãƒ¼ãƒ³ã§æ§‹ç¯‰
const pipeline = new AudioPipelineBuilder()
    .addProcessor(new VADProcessor({
        threshold: 0.01,
        debounce: 300,
        minSpeechMs: 500
    }))
    .addProcessor(new ResamplerProcessor({
        targetSampleRate: 24000,
        quality: 'high'
    }))
    .addProcessor(new EncoderProcessor({
        format: 'pcm16'
    }))
    .build();

await pipeline.initialize();

// éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã‚’å‡¦ç†
const result = await pipeline.process({
    samples: audioSamples,
    sampleRate: 48000,
    channels: 1,
    timestamp: Date.now()
});

if (result.success) {
    console.log('Processed:', result.data);
} else {
    console.error('Error:', result.error);
}
```

---

### 3. ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒ©ãƒ¼

```typescript
import { ErrorHandler, AppError, ErrorCategory, ErrorSeverity, RecoveryStrategy } from './src/services';

const errorHandler = new ErrorHandler({
    enableLogging: true,
    enableUserNotification: true,
    enableAutoRecovery: true,
    maxRetries: 3,
    retryDelay: 1000
});

// ã‚«ã‚¹ã‚¿ãƒ ã‚¨ãƒ©ãƒ¼ã®ä½œæˆ
const error = new AppError({
    code: 'CUSTOM_ERROR',
    message: 'Something went wrong',
    category: ErrorCategory.SYSTEM,
    severity: ErrorSeverity.ERROR,
    recoveryStrategy: RecoveryStrategy.RETRY,
    userMessage: 'ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚å†è©¦è¡Œã—ã¦ã„ã¾ã™...',
    retryable: true
});

// ã‚¨ãƒ©ãƒ¼å‡¦ç†
const recovered = await errorHandler.handleError(error);

if (recovered) {
    console.log('Error recovered successfully');
} else {
    console.log('Manual intervention required');
}

// ã‚¨ãƒ©ãƒ¼å±¥æ­´ã®å–å¾—
const history = errorHandler.getErrorHistory();
console.log('Error history:', history);
```

---

### 4. é…å»¶æœ€é©åŒ–

```typescript
import { LatencyOptimizer } from './src/services';

const optimizer = new LatencyOptimizer({
    enablePreconnect: true,
    enableStreaming: true,
    enableAsync: true,
    chunkSizeMs: 100,
    bufferSizeMs: 300
});

// WebSocket äº‹å‰æ¥ç¶š
await optimizer.preconnectWebSocket();

// ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°é–‹å§‹
await optimizer.startStreaming();

// éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã‚’ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°é€ä¿¡
await optimizer.streamAudio(audioBuffer);

// éåŒæœŸé–¢æ•°å‘¼ã³å‡ºã—
await optimizer.callFunctionAsync(
    async () => {
        // é‡ã„å‡¦ç†
        return await heavyOperation();
    },
    (result) => console.log('Success:', result),
    (error) => console.error('Error:', error)
);

// é…å»¶æ¸¬å®š
const { result, latency } = await optimizer.measureLatency(async () => {
    return await someOperation();
});
console.log(`Operation completed in ${latency}ms`);

// çµ±è¨ˆæƒ…å ±
const stats = optimizer.getStats();
console.log('Queue size:', stats.queueSize);
console.log('Is processing:', stats.isProcessing);
```

---

### 5. ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£

#### éŸ³å£°ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£

```typescript
import { AudioUtils } from './src/utils';

// Float32 â†’ PCM16 å¤‰æ›
const pcm16 = AudioUtils.floatTo16BitPCM(float32Samples);

// Base64 ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰
const base64 = AudioUtils.arrayBufferToBase64(audioBuffer);

// RMS è¨ˆç®—
const rms = AudioUtils.calculateRMS(samples);

// ç„¡éŸ³æ¤œå‡º
const isSilent = AudioUtils.isSilence(samples, 0.01);

// éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã‚’æ­£è¦åŒ–
const normalized = AudioUtils.normalizeAudio(samples);
```

#### å…±é€šãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£

```typescript
import { CommonUtils } from './src/utils';

// æ™‚é–“ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ
const timeStr = CommonUtils.formatTime(3665); // "01:01:05"

// è¨€èªåå–å¾—
const langName = CommonUtils.getLanguageName('ja'); // "Japanese"
const nativeName = CommonUtils.getNativeLanguageName('ja'); // "æ—¥æœ¬èª"

// ãƒ‡ãƒã‚¦ãƒ³ã‚¹
const debouncedFn = CommonUtils.debounce(() => {
    console.log('Debounced!');
}, 300);

// ãƒªãƒˆãƒ©ã‚¤
const result = await CommonUtils.retry(async () => {
    return await unstableOperation();
}, 3, 1000);

// ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆä»˜ãå®Ÿè¡Œ
const result = await CommonUtils.withTimeout(
    longRunningOperation(),
    5000,
    'Operation timed out'
);
```

---

## è¨­å®šæ–¹æ³•

### ç’°å¢ƒå¤‰æ•°

`.env` ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆ:

```env
OPENAI_API_KEY=your-api-key
OPENAI_REALTIME_MODEL=gpt-realtime-2025-08-28
OPENAI_CHAT_MODEL=gpt-4o
OPENAI_REALTIME_URL=wss://api.openai.com/v1/realtime
DEBUG_MODE=false
```

### ãƒ—ãƒ­ã‚°ãƒ©ãƒ ã§ã®è¨­å®š

```typescript
import { AppConfig } from './src/config';

// ç’°å¢ƒå¤‰æ•°ã‹ã‚‰èª­ã¿è¾¼ã¿
AppConfig.loadFromEnv();

// æ‰‹å‹•è¨­å®š
AppConfig.API.REALTIME_MODEL = 'gpt-realtime-2025-08-28';
AppConfig.AUDIO_PRESET = 'LOW_LATENCY';

// è¨­å®šæ¤œè¨¼
const validation = AppConfig.validate();
if (!validation.valid) {
    console.error('Configuration errors:', validation.errors);
}

// ç¾åœ¨ã®ãƒ—ãƒªã‚»ãƒƒãƒˆå–å¾—
const preset = AppConfig.getAudioPreset();
console.log('Buffer size:', preset.BUFFER_SIZE);
```

---

## ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°

### WebSocket æ¥ç¶šã‚¨ãƒ©ãƒ¼

**å•é¡Œ**: WebSocket æ¥ç¶šãŒå¤±æ•—ã™ã‚‹

**è§£æ±ºç­–**:
1. API ã‚­ãƒ¼ã‚’ç¢ºèª
2. ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯æ¥ç¶šã‚’ç¢ºèª
3. CORS è¨­å®šã‚’ç¢ºèªï¼ˆãƒ–ãƒ©ã‚¦ã‚¶ç’°å¢ƒï¼‰
4. ãƒ—ãƒ­ã‚­ã‚·è¨­å®šã‚’ç¢ºèª

```typescript
// ãƒ‡ãƒãƒƒã‚°ãƒ­ã‚°ã‚’æœ‰åŠ¹åŒ–
AppConfig.DEBUG_MODE = true;

// æ¥ç¶šã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã‚’å»¶é•·
await adapter.initialize({
    ...config,
    connectionTimeout: 60000 // 60ç§’
});
```

### éŸ³å£°å‡¦ç†ã‚¨ãƒ©ãƒ¼

**å•é¡Œ**: éŸ³å£°ãŒæ­£ã—ãå‡¦ç†ã•ã‚Œãªã„

**è§£æ±ºç­–**:
1. ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ãƒ¬ãƒ¼ãƒˆã‚’ç¢ºèªï¼ˆ24kHz å¿…é ˆï¼‰
2. ãƒãƒ£ãƒ³ãƒãƒ«æ•°ã‚’ç¢ºèªï¼ˆãƒ¢ãƒãƒ©ãƒ«æ¨å¥¨ï¼‰
3. VAD é–¾å€¤ã‚’èª¿æ•´

```typescript
// VAD æ„Ÿåº¦ã‚’èª¿æ•´
const vad = new VADProcessor({
    threshold: 0.005, // ã‚ˆã‚Šæ•æ„Ÿã«
    debounce: 200     // ã‚ˆã‚ŠçŸ­ã
});
```

### ãƒ¡ãƒ¢ãƒªãƒªãƒ¼ã‚¯

**å•é¡Œ**: é•·æ™‚é–“ä½¿ç”¨ã§ãƒ¡ãƒ¢ãƒªãŒå¢—åŠ 

**è§£æ±ºç­–**:
1. ä½¿ç”¨å¾Œã«å¿…ãš dispose ã‚’å‘¼ã¶
2. ã‚¤ãƒ™ãƒ³ãƒˆãƒªã‚¹ãƒŠãƒ¼ã‚’è§£é™¤

```typescript
// ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
await pipeline.dispose();
await adapter.dispose();
await optimizer.dispose();
```

---

## ãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹

### 1. ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°

```typescript
try {
    await adapter.connect();
} catch (error) {
    await errorHandler.handleError(error);
}
```

### 2. ãƒªã‚½ãƒ¼ã‚¹ç®¡ç†

```typescript
// ä½¿ç”¨å¾Œã¯å¿…ãšã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
try {
    // å‡¦ç†
} finally {
    await pipeline.dispose();
    await adapter.dispose();
}
```

### 3. ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æœ€é©åŒ–

```typescript
// äº‹å‰æ¥ç¶šã§åˆå›é…å»¶ã‚’å‰Šæ¸›
await optimizer.preconnectWebSocket();

// ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ã§é…å»¶ã‚’å‰Šæ¸›
await optimizer.startStreaming();
```

---

## ã‚µãƒ³ãƒ—ãƒ«ã‚³ãƒ¼ãƒ‰

å®Œå…¨ãªã‚µãƒ³ãƒ—ãƒ«ã‚³ãƒ¼ãƒ‰ã¯ `examples/` ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’å‚ç…§ã—ã¦ãã ã•ã„ã€‚

---

**VoiceTranslate Pro Team**  
**Version 2.0.0**

